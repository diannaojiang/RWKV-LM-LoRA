{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7cd0cc6-6245-45db-853c-538c4a09e47c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T10:14:28.429366Z",
     "iopub.status.busy": "2023-04-01T10:14:28.429297Z",
     "iopub.status.idle": "2023-04-01T10:14:35.892978Z",
     "shell.execute_reply": "2023-04-01T10:14:35.892317Z",
     "shell.execute_reply.started": "2023-04-01T10:14:28.429359Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RWKV_HEAD_QK_DIM 0 RWKV_JIT_ON 1\n",
      "\n",
      "loading... ../RWKV-4-Pile-7B-EngChn-test5-20230326\n",
      "merging blocks.4.ffn.key.lora_A and blocks.4.ffn.key.lora_B into blocks.4.ffn.key.weight\n",
      "merging blocks.20.att.receptance.lora_A and blocks.20.att.receptance.lora_B into blocks.20.att.receptance.weight\n",
      "merging blocks.9.att.key.lora_A and blocks.9.att.key.lora_B into blocks.9.att.key.weight\n",
      "merging blocks.5.att.receptance.lora_A and blocks.5.att.receptance.lora_B into blocks.5.att.receptance.weight\n",
      "merging blocks.15.att.key.lora_A and blocks.15.att.key.lora_B into blocks.15.att.key.weight\n",
      "merging blocks.15.ffn.key.lora_A and blocks.15.ffn.key.lora_B into blocks.15.ffn.key.weight\n",
      "merging blocks.20.att.value.lora_A and blocks.20.att.value.lora_B into blocks.20.att.value.weight\n",
      "merging blocks.15.ffn.value.lora_A and blocks.15.ffn.value.lora_B into blocks.15.ffn.value.weight\n",
      "merging blocks.16.att.value.lora_A and blocks.16.att.value.lora_B into blocks.16.att.value.weight\n",
      "merging blocks.16.att.receptance.lora_A and blocks.16.att.receptance.lora_B into blocks.16.att.receptance.weight\n",
      "merging blocks.21.att.value.lora_A and blocks.21.att.value.lora_B into blocks.21.att.value.weight\n",
      "merging blocks.22.ffn.value.lora_A and blocks.22.ffn.value.lora_B into blocks.22.ffn.value.weight\n",
      "merging blocks.24.ffn.key.lora_A and blocks.24.ffn.key.lora_B into blocks.24.ffn.key.weight\n",
      "merging blocks.10.ffn.receptance.lora_A and blocks.10.ffn.receptance.lora_B into blocks.10.ffn.receptance.weight\n",
      "merging blocks.30.ffn.receptance.lora_A and blocks.30.ffn.receptance.lora_B into blocks.30.ffn.receptance.weight\n",
      "merging blocks.0.ffn.receptance.lora_A and blocks.0.ffn.receptance.lora_B into blocks.0.ffn.receptance.weight\n",
      "merging blocks.16.ffn.receptance.lora_A and blocks.16.ffn.receptance.lora_B into blocks.16.ffn.receptance.weight\n",
      "merging blocks.12.ffn.value.lora_A and blocks.12.ffn.value.lora_B into blocks.12.ffn.value.weight\n",
      "merging blocks.22.att.key.lora_A and blocks.22.att.key.lora_B into blocks.22.att.key.weight\n",
      "merging blocks.1.ffn.receptance.lora_A and blocks.1.ffn.receptance.lora_B into blocks.1.ffn.receptance.weight\n",
      "merging blocks.22.ffn.receptance.lora_A and blocks.22.ffn.receptance.lora_B into blocks.22.ffn.receptance.weight\n",
      "merging blocks.5.att.key.lora_A and blocks.5.att.key.lora_B into blocks.5.att.key.weight\n",
      "merging blocks.28.ffn.key.lora_A and blocks.28.ffn.key.lora_B into blocks.28.ffn.key.weight\n",
      "merging blocks.22.ffn.key.lora_A and blocks.22.ffn.key.lora_B into blocks.22.ffn.key.weight\n",
      "merging blocks.25.att.receptance.lora_A and blocks.25.att.receptance.lora_B into blocks.25.att.receptance.weight\n",
      "merging blocks.23.att.receptance.lora_A and blocks.23.att.receptance.lora_B into blocks.23.att.receptance.weight\n",
      "merging blocks.7.ffn.value.lora_A and blocks.7.ffn.value.lora_B into blocks.7.ffn.value.weight\n",
      "merging blocks.28.ffn.receptance.lora_A and blocks.28.ffn.receptance.lora_B into blocks.28.ffn.receptance.weight\n",
      "merging blocks.0.att.receptance.lora_A and blocks.0.att.receptance.lora_B into blocks.0.att.receptance.weight\n",
      "merging blocks.21.ffn.receptance.lora_A and blocks.21.ffn.receptance.lora_B into blocks.21.ffn.receptance.weight\n",
      "merging blocks.5.att.value.lora_A and blocks.5.att.value.lora_B into blocks.5.att.value.weight\n",
      "merging blocks.31.ffn.value.lora_A and blocks.31.ffn.value.lora_B into blocks.31.ffn.value.weight\n",
      "merging blocks.24.ffn.receptance.lora_A and blocks.24.ffn.receptance.lora_B into blocks.24.ffn.receptance.weight\n",
      "merging blocks.18.att.key.lora_A and blocks.18.att.key.lora_B into blocks.18.att.key.weight\n",
      "merging blocks.22.att.receptance.lora_A and blocks.22.att.receptance.lora_B into blocks.22.att.receptance.weight\n",
      "merging blocks.8.att.key.lora_A and blocks.8.att.key.lora_B into blocks.8.att.key.weight\n",
      "merging blocks.3.att.receptance.lora_A and blocks.3.att.receptance.lora_B into blocks.3.att.receptance.weight\n",
      "merging blocks.2.ffn.key.lora_A and blocks.2.ffn.key.lora_B into blocks.2.ffn.key.weight\n",
      "merging blocks.26.ffn.receptance.lora_A and blocks.26.ffn.receptance.lora_B into blocks.26.ffn.receptance.weight\n",
      "merging blocks.27.att.receptance.lora_A and blocks.27.att.receptance.lora_B into blocks.27.att.receptance.weight\n",
      "merging blocks.10.att.key.lora_A and blocks.10.att.key.lora_B into blocks.10.att.key.weight\n",
      "merging blocks.16.att.key.lora_A and blocks.16.att.key.lora_B into blocks.16.att.key.weight\n",
      "merging blocks.25.att.value.lora_A and blocks.25.att.value.lora_B into blocks.25.att.value.weight\n",
      "merging blocks.6.att.key.lora_A and blocks.6.att.key.lora_B into blocks.6.att.key.weight\n",
      "merging blocks.31.att.key.lora_A and blocks.31.att.key.lora_B into blocks.31.att.key.weight\n",
      "merging blocks.21.att.key.lora_A and blocks.21.att.key.lora_B into blocks.21.att.key.weight\n",
      "merging blocks.10.att.value.lora_A and blocks.10.att.value.lora_B into blocks.10.att.value.weight\n",
      "merging blocks.26.ffn.key.lora_A and blocks.26.ffn.key.lora_B into blocks.26.ffn.key.weight\n",
      "merging blocks.29.att.receptance.lora_A and blocks.29.att.receptance.lora_B into blocks.29.att.receptance.weight\n",
      "merging blocks.2.att.value.lora_A and blocks.2.att.value.lora_B into blocks.2.att.value.weight\n",
      "merging blocks.20.ffn.key.lora_A and blocks.20.ffn.key.lora_B into blocks.20.ffn.key.weight\n",
      "merging blocks.26.ffn.value.lora_A and blocks.26.ffn.value.lora_B into blocks.26.ffn.value.weight\n",
      "merging blocks.7.att.receptance.lora_A and blocks.7.att.receptance.lora_B into blocks.7.att.receptance.weight\n",
      "merging blocks.31.att.value.lora_A and blocks.31.att.value.lora_B into blocks.31.att.value.weight\n",
      "merging blocks.17.att.value.lora_A and blocks.17.att.value.lora_B into blocks.17.att.value.weight\n",
      "merging blocks.5.ffn.key.lora_A and blocks.5.ffn.key.lora_B into blocks.5.ffn.key.weight\n",
      "merging blocks.4.att.value.lora_A and blocks.4.att.value.lora_B into blocks.4.att.value.weight\n",
      "merging blocks.27.ffn.key.lora_A and blocks.27.ffn.key.lora_B into blocks.27.ffn.key.weight\n",
      "merging blocks.27.ffn.receptance.lora_A and blocks.27.ffn.receptance.lora_B into blocks.27.ffn.receptance.weight\n",
      "merging blocks.20.ffn.receptance.lora_A and blocks.20.ffn.receptance.lora_B into blocks.20.ffn.receptance.weight\n",
      "merging blocks.17.ffn.key.lora_A and blocks.17.ffn.key.lora_B into blocks.17.ffn.key.weight\n",
      "merging blocks.9.att.value.lora_A and blocks.9.att.value.lora_B into blocks.9.att.value.weight\n",
      "merging blocks.17.ffn.receptance.lora_A and blocks.17.ffn.receptance.lora_B into blocks.17.ffn.receptance.weight\n",
      "merging blocks.24.ffn.value.lora_A and blocks.24.ffn.value.lora_B into blocks.24.ffn.value.weight\n",
      "merging blocks.29.att.key.lora_A and blocks.29.att.key.lora_B into blocks.29.att.key.weight\n",
      "merging blocks.18.ffn.key.lora_A and blocks.18.ffn.key.lora_B into blocks.18.ffn.key.weight\n",
      "merging blocks.7.ffn.key.lora_A and blocks.7.ffn.key.lora_B into blocks.7.ffn.key.weight\n",
      "merging blocks.15.att.receptance.lora_A and blocks.15.att.receptance.lora_B into blocks.15.att.receptance.weight\n",
      "merging blocks.6.ffn.value.lora_A and blocks.6.ffn.value.lora_B into blocks.6.ffn.value.weight\n",
      "merging blocks.6.ffn.receptance.lora_A and blocks.6.ffn.receptance.lora_B into blocks.6.ffn.receptance.weight\n",
      "merging blocks.27.att.value.lora_A and blocks.27.att.value.lora_B into blocks.27.att.value.weight\n",
      "merging blocks.13.ffn.receptance.lora_A and blocks.13.ffn.receptance.lora_B into blocks.13.ffn.receptance.weight\n",
      "merging blocks.3.ffn.receptance.lora_A and blocks.3.ffn.receptance.lora_B into blocks.3.ffn.receptance.weight\n",
      "merging blocks.21.ffn.value.lora_A and blocks.21.ffn.value.lora_B into blocks.21.ffn.value.weight\n",
      "merging blocks.21.att.receptance.lora_A and blocks.21.att.receptance.lora_B into blocks.21.att.receptance.weight\n",
      "merging blocks.25.ffn.value.lora_A and blocks.25.ffn.value.lora_B into blocks.25.ffn.value.weight\n",
      "merging blocks.10.att.receptance.lora_A and blocks.10.att.receptance.lora_B into blocks.10.att.receptance.weight\n",
      "merging blocks.26.att.value.lora_A and blocks.26.att.value.lora_B into blocks.26.att.value.weight\n",
      "merging blocks.0.ffn.key.lora_A and blocks.0.ffn.key.lora_B into blocks.0.ffn.key.weight\n",
      "merging blocks.11.ffn.receptance.lora_A and blocks.11.ffn.receptance.lora_B into blocks.11.ffn.receptance.weight\n",
      "merging blocks.19.att.key.lora_A and blocks.19.att.key.lora_B into blocks.19.att.key.weight\n",
      "merging blocks.18.ffn.receptance.lora_A and blocks.18.ffn.receptance.lora_B into blocks.18.ffn.receptance.weight\n",
      "merging blocks.8.ffn.value.lora_A and blocks.8.ffn.value.lora_B into blocks.8.ffn.value.weight\n",
      "merging blocks.11.ffn.value.lora_A and blocks.11.ffn.value.lora_B into blocks.11.ffn.value.weight\n",
      "merging blocks.13.ffn.value.lora_A and blocks.13.ffn.value.lora_B into blocks.13.ffn.value.weight\n",
      "merging blocks.6.ffn.key.lora_A and blocks.6.ffn.key.lora_B into blocks.6.ffn.key.weight\n",
      "merging blocks.9.ffn.value.lora_A and blocks.9.ffn.value.lora_B into blocks.9.ffn.value.weight\n",
      "merging blocks.8.ffn.receptance.lora_A and blocks.8.ffn.receptance.lora_B into blocks.8.ffn.receptance.weight\n",
      "merging blocks.9.ffn.receptance.lora_A and blocks.9.ffn.receptance.lora_B into blocks.9.ffn.receptance.weight\n",
      "merging blocks.14.att.value.lora_A and blocks.14.att.value.lora_B into blocks.14.att.value.weight\n",
      "merging blocks.30.att.receptance.lora_A and blocks.30.att.receptance.lora_B into blocks.30.att.receptance.weight\n",
      "merging blocks.2.ffn.receptance.lora_A and blocks.2.ffn.receptance.lora_B into blocks.2.ffn.receptance.weight\n",
      "merging blocks.24.att.value.lora_A and blocks.24.att.value.lora_B into blocks.24.att.value.weight\n",
      "merging blocks.16.ffn.value.lora_A and blocks.16.ffn.value.lora_B into blocks.16.ffn.value.weight\n",
      "merging blocks.14.ffn.receptance.lora_A and blocks.14.ffn.receptance.lora_B into blocks.14.ffn.receptance.weight\n",
      "merging blocks.25.ffn.receptance.lora_A and blocks.25.ffn.receptance.lora_B into blocks.25.ffn.receptance.weight\n",
      "merging blocks.7.att.key.lora_A and blocks.7.att.key.lora_B into blocks.7.att.key.weight\n",
      "merging blocks.15.ffn.receptance.lora_A and blocks.15.ffn.receptance.lora_B into blocks.15.ffn.receptance.weight\n",
      "merging blocks.31.att.receptance.lora_A and blocks.31.att.receptance.lora_B into blocks.31.att.receptance.weight\n",
      "merging blocks.4.att.key.lora_A and blocks.4.att.key.lora_B into blocks.4.att.key.weight\n",
      "merging blocks.1.ffn.value.lora_A and blocks.1.ffn.value.lora_B into blocks.1.ffn.value.weight\n",
      "merging blocks.14.att.receptance.lora_A and blocks.14.att.receptance.lora_B into blocks.14.att.receptance.weight\n",
      "merging blocks.5.ffn.receptance.lora_A and blocks.5.ffn.receptance.lora_B into blocks.5.ffn.receptance.weight\n",
      "merging blocks.6.att.value.lora_A and blocks.6.att.value.lora_B into blocks.6.att.value.weight\n",
      "merging blocks.14.ffn.value.lora_A and blocks.14.ffn.value.lora_B into blocks.14.ffn.value.weight\n",
      "merging blocks.27.ffn.value.lora_A and blocks.27.ffn.value.lora_B into blocks.27.ffn.value.weight\n",
      "merging blocks.21.ffn.key.lora_A and blocks.21.ffn.key.lora_B into blocks.21.ffn.key.weight\n",
      "merging blocks.14.ffn.key.lora_A and blocks.14.ffn.key.lora_B into blocks.14.ffn.key.weight\n",
      "merging blocks.4.ffn.value.lora_A and blocks.4.ffn.value.lora_B into blocks.4.ffn.value.weight\n",
      "merging blocks.6.att.receptance.lora_A and blocks.6.att.receptance.lora_B into blocks.6.att.receptance.weight\n",
      "merging blocks.12.att.key.lora_A and blocks.12.att.key.lora_B into blocks.12.att.key.weight\n",
      "merging blocks.26.att.receptance.lora_A and blocks.26.att.receptance.lora_B into blocks.26.att.receptance.weight\n",
      "merging blocks.16.ffn.key.lora_A and blocks.16.ffn.key.lora_B into blocks.16.ffn.key.weight\n",
      "merging blocks.4.ffn.receptance.lora_A and blocks.4.ffn.receptance.lora_B into blocks.4.ffn.receptance.weight\n",
      "merging blocks.24.att.receptance.lora_A and blocks.24.att.receptance.lora_B into blocks.24.att.receptance.weight\n",
      "merging blocks.10.ffn.value.lora_A and blocks.10.ffn.value.lora_B into blocks.10.ffn.value.weight\n",
      "merging blocks.9.ffn.key.lora_A and blocks.9.ffn.key.lora_B into blocks.9.ffn.key.weight\n",
      "merging blocks.12.ffn.key.lora_A and blocks.12.ffn.key.lora_B into blocks.12.ffn.key.weight\n",
      "merging blocks.29.ffn.key.lora_A and blocks.29.ffn.key.lora_B into blocks.29.ffn.key.weight\n",
      "merging blocks.29.ffn.receptance.lora_A and blocks.29.ffn.receptance.lora_B into blocks.29.ffn.receptance.weight\n",
      "merging blocks.25.ffn.key.lora_A and blocks.25.ffn.key.lora_B into blocks.25.ffn.key.weight\n",
      "merging blocks.17.ffn.value.lora_A and blocks.17.ffn.value.lora_B into blocks.17.ffn.value.weight\n",
      "merging blocks.26.att.key.lora_A and blocks.26.att.key.lora_B into blocks.26.att.key.weight\n",
      "merging blocks.27.att.key.lora_A and blocks.27.att.key.lora_B into blocks.27.att.key.weight\n",
      "merging blocks.7.ffn.receptance.lora_A and blocks.7.ffn.receptance.lora_B into blocks.7.ffn.receptance.weight\n",
      "merging blocks.8.att.receptance.lora_A and blocks.8.att.receptance.lora_B into blocks.8.att.receptance.weight\n",
      "merging blocks.12.ffn.receptance.lora_A and blocks.12.ffn.receptance.lora_B into blocks.12.ffn.receptance.weight\n",
      "merging blocks.28.att.receptance.lora_A and blocks.28.att.receptance.lora_B into blocks.28.att.receptance.weight\n",
      "merging blocks.1.att.key.lora_A and blocks.1.att.key.lora_B into blocks.1.att.key.weight\n",
      "merging blocks.31.ffn.receptance.lora_A and blocks.31.ffn.receptance.lora_B into blocks.31.ffn.receptance.weight\n",
      "merging blocks.29.ffn.value.lora_A and blocks.29.ffn.value.lora_B into blocks.29.ffn.value.weight\n",
      "merging blocks.14.att.key.lora_A and blocks.14.att.key.lora_B into blocks.14.att.key.weight\n",
      "merging blocks.23.ffn.receptance.lora_A and blocks.23.ffn.receptance.lora_B into blocks.23.ffn.receptance.weight\n",
      "merging blocks.28.att.key.lora_A and blocks.28.att.key.lora_B into blocks.28.att.key.weight\n",
      "merging blocks.18.ffn.value.lora_A and blocks.18.ffn.value.lora_B into blocks.18.ffn.value.weight\n",
      "merging blocks.11.att.key.lora_A and blocks.11.att.key.lora_B into blocks.11.att.key.weight\n",
      "merging blocks.1.ffn.key.lora_A and blocks.1.ffn.key.lora_B into blocks.1.ffn.key.weight\n",
      "merging blocks.9.att.receptance.lora_A and blocks.9.att.receptance.lora_B into blocks.9.att.receptance.weight\n",
      "merging blocks.24.att.key.lora_A and blocks.24.att.key.lora_B into blocks.24.att.key.weight\n",
      "merging blocks.10.ffn.key.lora_A and blocks.10.ffn.key.lora_B into blocks.10.ffn.key.weight\n",
      "merging blocks.28.ffn.value.lora_A and blocks.28.ffn.value.lora_B into blocks.28.ffn.value.weight\n",
      "merging blocks.3.ffn.value.lora_A and blocks.3.ffn.value.lora_B into blocks.3.ffn.value.weight\n",
      "merging blocks.23.ffn.value.lora_A and blocks.23.ffn.value.lora_B into blocks.23.ffn.value.weight\n",
      "merging blocks.19.att.value.lora_A and blocks.19.att.value.lora_B into blocks.19.att.value.weight\n",
      "merging blocks.4.att.receptance.lora_A and blocks.4.att.receptance.lora_B into blocks.4.att.receptance.weight\n",
      "merging blocks.13.ffn.key.lora_A and blocks.13.ffn.key.lora_B into blocks.13.ffn.key.weight\n",
      "merging blocks.7.att.value.lora_A and blocks.7.att.value.lora_B into blocks.7.att.value.weight\n",
      "merging blocks.23.att.value.lora_A and blocks.23.att.value.lora_B into blocks.23.att.value.weight\n",
      "merging blocks.1.att.receptance.lora_A and blocks.1.att.receptance.lora_B into blocks.1.att.receptance.weight\n",
      "merging blocks.20.ffn.value.lora_A and blocks.20.ffn.value.lora_B into blocks.20.ffn.value.weight\n",
      "merging blocks.23.att.key.lora_A and blocks.23.att.key.lora_B into blocks.23.att.key.weight\n",
      "merging blocks.2.att.key.lora_A and blocks.2.att.key.lora_B into blocks.2.att.key.weight\n",
      "merging blocks.2.ffn.value.lora_A and blocks.2.ffn.value.lora_B into blocks.2.ffn.value.weight\n",
      "merging blocks.15.att.value.lora_A and blocks.15.att.value.lora_B into blocks.15.att.value.weight\n",
      "merging blocks.30.att.value.lora_A and blocks.30.att.value.lora_B into blocks.30.att.value.weight\n",
      "merging blocks.11.ffn.key.lora_A and blocks.11.ffn.key.lora_B into blocks.11.ffn.key.weight\n",
      "merging blocks.11.att.receptance.lora_A and blocks.11.att.receptance.lora_B into blocks.11.att.receptance.weight\n",
      "merging blocks.13.att.receptance.lora_A and blocks.13.att.receptance.lora_B into blocks.13.att.receptance.weight\n",
      "merging blocks.20.att.key.lora_A and blocks.20.att.key.lora_B into blocks.20.att.key.weight\n",
      "merging blocks.18.att.receptance.lora_A and blocks.18.att.receptance.lora_B into blocks.18.att.receptance.weight\n",
      "merging blocks.0.att.key.lora_A and blocks.0.att.key.lora_B into blocks.0.att.key.weight\n",
      "merging blocks.11.att.value.lora_A and blocks.11.att.value.lora_B into blocks.11.att.value.weight\n",
      "merging blocks.19.ffn.value.lora_A and blocks.19.ffn.value.lora_B into blocks.19.ffn.value.weight\n",
      "merging blocks.29.att.value.lora_A and blocks.29.att.value.lora_B into blocks.29.att.value.weight\n",
      "merging blocks.12.att.receptance.lora_A and blocks.12.att.receptance.lora_B into blocks.12.att.receptance.weight\n",
      "merging blocks.23.ffn.key.lora_A and blocks.23.ffn.key.lora_B into blocks.23.ffn.key.weight\n",
      "merging blocks.5.ffn.value.lora_A and blocks.5.ffn.value.lora_B into blocks.5.ffn.value.weight\n",
      "merging blocks.8.att.value.lora_A and blocks.8.att.value.lora_B into blocks.8.att.value.weight\n",
      "merging blocks.0.ffn.value.lora_A and blocks.0.ffn.value.lora_B into blocks.0.ffn.value.weight\n",
      "merging blocks.18.att.value.lora_A and blocks.18.att.value.lora_B into blocks.18.att.value.weight\n",
      "merging blocks.3.att.value.lora_A and blocks.3.att.value.lora_B into blocks.3.att.value.weight\n",
      "merging blocks.22.att.value.lora_A and blocks.22.att.value.lora_B into blocks.22.att.value.weight\n",
      "merging blocks.28.att.value.lora_A and blocks.28.att.value.lora_B into blocks.28.att.value.weight\n",
      "merging blocks.13.att.value.lora_A and blocks.13.att.value.lora_B into blocks.13.att.value.weight\n",
      "merging blocks.13.att.key.lora_A and blocks.13.att.key.lora_B into blocks.13.att.key.weight\n",
      "merging blocks.30.ffn.value.lora_A and blocks.30.ffn.value.lora_B into blocks.30.ffn.value.weight\n",
      "merging blocks.1.att.value.lora_A and blocks.1.att.value.lora_B into blocks.1.att.value.weight\n",
      "merging blocks.0.att.value.lora_A and blocks.0.att.value.lora_B into blocks.0.att.value.weight\n",
      "merging blocks.12.att.value.lora_A and blocks.12.att.value.lora_B into blocks.12.att.value.weight\n",
      "merging blocks.25.att.key.lora_A and blocks.25.att.key.lora_B into blocks.25.att.key.weight\n",
      "merging blocks.8.ffn.key.lora_A and blocks.8.ffn.key.lora_B into blocks.8.ffn.key.weight\n",
      "merging blocks.19.ffn.key.lora_A and blocks.19.ffn.key.lora_B into blocks.19.ffn.key.weight\n",
      "merging blocks.2.att.receptance.lora_A and blocks.2.att.receptance.lora_B into blocks.2.att.receptance.weight\n",
      "merging blocks.17.att.key.lora_A and blocks.17.att.key.lora_B into blocks.17.att.key.weight\n",
      "merging blocks.17.att.receptance.lora_A and blocks.17.att.receptance.lora_B into blocks.17.att.receptance.weight\n",
      "merging blocks.31.ffn.key.lora_A and blocks.31.ffn.key.lora_B into blocks.31.ffn.key.weight\n",
      "merging blocks.30.ffn.key.lora_A and blocks.30.ffn.key.lora_B into blocks.30.ffn.key.weight\n",
      "merging blocks.3.att.key.lora_A and blocks.3.att.key.lora_B into blocks.3.att.key.weight\n",
      "merging blocks.30.att.key.lora_A and blocks.30.att.key.lora_B into blocks.30.att.key.weight\n",
      "merging blocks.19.ffn.receptance.lora_A and blocks.19.ffn.receptance.lora_B into blocks.19.ffn.receptance.weight\n",
      "merging blocks.19.att.receptance.lora_A and blocks.19.att.receptance.lora_B into blocks.19.att.receptance.weight\n",
      "merging blocks.3.ffn.key.lora_A and blocks.3.ffn.key.lora_B into blocks.3.ffn.key.weight\n",
      "emb.weight                               float16    cpu\n",
      "blocks.0.ln1.weight                      float16    cuda:0\n",
      "blocks.0.ln1.bias                        float16    cuda:0\n",
      "blocks.0.ln2.weight                      float16    cuda:0\n",
      "blocks.0.ln2.bias                        float16    cuda:0\n",
      "blocks.0.ln0.weight                      float16    cuda:0\n",
      "blocks.0.ln0.bias                        float16    cuda:0\n",
      "blocks.0.att.time_decay                  float32    cuda:0\n",
      "blocks.0.att.time_first                  float32    cuda:0\n",
      "blocks.0.att.time_mix_k                  float16    cuda:0\n",
      "blocks.0.att.time_mix_v                  float16    cuda:0\n",
      "blocks.0.att.time_mix_r                  float16    cuda:0\n",
      "blocks.0.att.key.weight                  float16    cuda:0\n",
      "blocks.0.att.value.weight                float16    cuda:0\n",
      "blocks.0.att.receptance.weight           float16    cuda:0\n",
      "blocks.0.att.output.weight               float16    cuda:0\n",
      "blocks.0.ffn.time_mix_k                  float16    cuda:0\n",
      "blocks.0.ffn.time_mix_r                  float16    cuda:0\n",
      "blocks.0.ffn.key.weight                  float16    cuda:0\n",
      "blocks.0.ffn.receptance.weight           float16    cuda:0\n",
      "blocks.0.ffn.value.weight                float16    cuda:0\n",
      "..............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "ln_out.weight                            float16    cuda:0\n",
      "ln_out.bias                              float16    cuda:0\n",
      "head.weight                              float16    cuda:0\n",
      "\n",
      "Run prompt...\n",
      "### prompt ###\n",
      "[\n",
      "\n",
      "]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"RWKV_JIT_ON\"] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import sys\n",
    "import gc\n",
    "import types\n",
    "import copy\n",
    "from src.model_run import RWKV_RNN\n",
    "import numpy as np\n",
    "import torch\n",
    "from src.utils import TOKENIZER\n",
    "import json\n",
    "import re\n",
    "import datetime\n",
    "import csv\n",
    "# os.chdir(\"/app/CSS_AI\")\n",
    "\n",
    "# from flask import Flask, request, jsonify\n",
    "# from gevent.pywsgi import WSGIServer\n",
    "# import requests\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "np.set_printoptions(precision=4, suppress=True, linewidth=200)\n",
    "\n",
    "WORD_NAME = [\n",
    "    \"20B_tokenizer.json\",\n",
    "    \"20B_tokenizer.json\",\n",
    "]  # [vocab, vocab] for Pile model\n",
    "UNKNOWN_CHAR = None\n",
    "tokenizer = TOKENIZER(WORD_NAME, UNKNOWN_CHAR=UNKNOWN_CHAR)\n",
    "\n",
    "args = types.SimpleNamespace()\n",
    "args.RUN_DEVICE = \"cuda\"  # 'cpu' (already very fast) // 'cuda'\n",
    "# fp32 (good for CPU) // fp16 (recommended for GPU) // bf16 (less accurate)\n",
    "args.FLOAT_MODE = \"fp16\"\n",
    "args.vocab_size = 50277\n",
    "args.head_qk = 0\n",
    "args.pre_ffn = 0\n",
    "args.grad_cp = 0\n",
    "args.my_pos_emb = 0\n",
    "\n",
    "\n",
    "args.lora_r = 8\n",
    "args.lora_alpha = 16\n",
    "\n",
    "# args.MODEL_NAME = '../RWKV-4-Pile-3B-EngChn-test4-20230115'\n",
    "# args.n_layer = 32\n",
    "# args.n_embd = 2560\n",
    "# args.ctx_len = 1024\n",
    "\n",
    "# args.MODEL_LORA = './model_lora'\n",
    "user = \"Bob\"\n",
    "bot = \"Alice\"\n",
    "interface = \":\"\n",
    "\n",
    "init_prompt = '''\n",
    "\n",
    "'''\n",
    "\n",
    "args.MODEL_NAME = '../RWKV-4-Pile-7B-EngChn-test5-20230326'\n",
    "args.n_layer = 32\n",
    "args.n_embd = 4096\n",
    "args.ctx_len = 1024\n",
    "\n",
    "# Modify this to use LoRA models; lora_r = 0 will not use LoRA weights.\n",
    "args.MODEL_LORA = './out_7b_tag/rwkv-1'\n",
    "# args.MODEL_LORA = './rwkv-raw'\n",
    "\n",
    "# user = \"Q\"\n",
    "# bot = \"A\"\n",
    "# interface = \":\"\n",
    "\n",
    "# init_prompt = '''\n",
    "# The following is a coherent verbose detailed conversation between a Chinese girl named {bot} and her friend {user}. \\\n",
    "# {bot} is very intelligent, creative and friendly. \\\n",
    "# {bot} likes to tell {user} a lot about herself and her opinions. \\\n",
    "# {bot} usually gives {user} kind, helpful and informative advices.\n",
    "# '''\n",
    "# HELP_MSG = '''指令:\n",
    "# 直接输入内容 --> 和机器人聊天，用\\\\n代表换行\n",
    "# +alt --> 让机器人换个回答\n",
    "# +reset --> 重置对话\n",
    "\n",
    "# +gen 某某内容 --> 续写任何中英文内容，用\\\\n代表换行\n",
    "# +qa 某某问题 --> 问独立的问题（忽略上下文），用\\\\n代表换行\n",
    "# +more --> 继续 +gen / +qa 的回答\n",
    "# +retry --> 换个 +gen / +qa 的回答\n",
    "\n",
    "# 现在可以输入内容和机器人聊天（注意它不怎么懂中文，它可能更懂英文）。请经常使用 +reset 重置机器人记忆。\n",
    "# '''\n",
    "\n",
    "# Load Model\n",
    "\n",
    "os.environ[\"RWKV_RUN_DEVICE\"] = args.RUN_DEVICE\n",
    "MODEL_NAME = args.MODEL_NAME\n",
    "\n",
    "print(f'loading... {MODEL_NAME}')\n",
    "model = RWKV_RNN(args)\n",
    "\n",
    "model_tokens = []\n",
    "\n",
    "current_state = None\n",
    "\n",
    "########################################################################################################\n",
    "\n",
    "\n",
    "def run_rnn(tokens, newline_adj=0):\n",
    "    global model_tokens, current_state\n",
    "    for i in range(len(tokens)):\n",
    "        model_tokens += [int(tokens[i])]\n",
    "        if i == len(tokens) - 1:\n",
    "            out, current_state = model.forward(model_tokens, current_state)\n",
    "        else:\n",
    "            current_state = model.forward(model_tokens,\n",
    "                                          current_state,\n",
    "                                          preprocess_only=True)\n",
    "\n",
    "    # print(f'### model ###\\n[{tokenizer.tokenizer.decode(model_tokens)}]')\n",
    "\n",
    "    out[0] = -999999999  # disable <|endoftext|>\n",
    "    out[187] += newline_adj\n",
    "    # if newline_adj > 0:\n",
    "    #     out[15] += newline_adj / 2 # '.'\n",
    "    return out\n",
    "\n",
    "\n",
    "all_state = {}\n",
    "\n",
    "\n",
    "def save_all_stat(srv, name, last_out):\n",
    "    n = f'{name}_{srv}'\n",
    "    all_state[n] = {}\n",
    "    all_state[n]['out'] = last_out\n",
    "    all_state[n]['rnn'] = copy.deepcopy(current_state)\n",
    "    all_state[n]['token'] = copy.deepcopy(model_tokens)\n",
    "\n",
    "\n",
    "def load_all_stat(srv, name):\n",
    "    global model_tokens, current_state\n",
    "    n = f'{name}_{srv}'\n",
    "    current_state = copy.deepcopy(all_state[n]['rnn'])\n",
    "    model_tokens = copy.deepcopy(all_state[n]['token'])\n",
    "    return all_state[n]['out']\n",
    "\n",
    "\n",
    "########################################################################################################\n",
    "\n",
    "# Run inference\n",
    "print(f'\\nRun prompt...')\n",
    "\n",
    "out = run_rnn(tokenizer.tokenizer.encode(init_prompt))\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "save_all_stat('', 'chat_init', out)\n",
    "\n",
    "srv_list = ['dummy_server']\n",
    "for s in srv_list:\n",
    "    save_all_stat(s, 'chat', out)\n",
    "\n",
    "print(f'### prompt ###\\n[{tokenizer.tokenizer.decode(model_tokens)}]\\n')\n",
    "\n",
    "# def reply_msg(msg):\n",
    "#     print(f'{bot}{interface} {msg}\\n')\n",
    "\n",
    "\n",
    "def on_message(message):\n",
    "    global model_tokens, current_state\n",
    "\n",
    "    srv = 'dummy_server'\n",
    "\n",
    "    msg = message.replace('\\\\n', '\\n').strip()\n",
    "    if len(msg) > 1000:\n",
    "        return ('your message is too long (max 1000 tokens)')\n",
    "\n",
    "    x_temp = 1.0\n",
    "    x_top_p = 0.85\n",
    "    if (\"-temp=\" in msg):\n",
    "        x_temp = float(msg.split(\"-temp=\")[1].split(\" \")[0])\n",
    "        msg = msg.replace(\"-temp=\" + f'{x_temp:g}', \"\")\n",
    "        # print(f\"temp: {x_temp}\")\n",
    "    if (\"-top_p=\" in msg):\n",
    "        x_top_p = float(msg.split(\"-top_p=\")[1].split(\" \")[0])\n",
    "        msg = msg.replace(\"-top_p=\" + f'{x_top_p:g}', \"\")\n",
    "        # print(f\"top_p: {x_top_p}\")\n",
    "    if x_temp <= 0.2:\n",
    "        x_temp = 0.2\n",
    "    if x_temp >= 5:\n",
    "        x_temp = 5\n",
    "    if x_top_p <= 0:\n",
    "        x_top_p = 0\n",
    "\n",
    "    if msg == '+reset':\n",
    "        out = load_all_stat('', 'chat_init')\n",
    "        save_all_stat(srv, 'chat', out)\n",
    "        return (\"Chat reset.\")\n",
    "\n",
    "    else:\n",
    "        if msg.lower() == '+alt':\n",
    "            try:\n",
    "                out = load_all_stat(srv, 'chat_pre')\n",
    "            except:\n",
    "                return\n",
    "        else:\n",
    "            out = load_all_stat(srv, 'chat')\n",
    "            new = f\"{user}{interface} {msg}\\n\\n{bot}{interface}\"\n",
    "            # print(f'### add ###\\n[{new}]')\n",
    "            out = run_rnn(tokenizer.tokenizer.encode(new),\n",
    "                          newline_adj=-999999999)\n",
    "            save_all_stat(srv, 'chat_pre', out)\n",
    "\n",
    "        begin = len(model_tokens)\n",
    "        out_last = begin\n",
    "        # print(f'{bot}{interface}', end='', flush=True)\n",
    "        out_string = \"\"\n",
    "        for i in range(999):\n",
    "            if i <= 0:\n",
    "                newline_adj = -999999999\n",
    "            elif i <= 30:\n",
    "                newline_adj = (i - 30) / 10\n",
    "            elif i <= 130:\n",
    "                newline_adj = 0\n",
    "            else:\n",
    "                newline_adj = (i - 130) * 0.25  # MUST END THE GENERATION\n",
    "            token = tokenizer.sample_logits(\n",
    "                out,\n",
    "                model_tokens,\n",
    "                args.ctx_len,\n",
    "                temperature=x_temp,\n",
    "                top_p_usual=x_top_p,\n",
    "                top_p_newline=x_top_p,\n",
    "            )\n",
    "            out = run_rnn([token], newline_adj=newline_adj)\n",
    "\n",
    "            xxx = tokenizer.tokenizer.decode(model_tokens[out_last:])\n",
    "            if '\\ufffd' not in xxx:\n",
    "                # print(xxx, end='', flush=True)\n",
    "                out_string += xxx\n",
    "                out_last = begin + i + 1\n",
    "\n",
    "            send_msg = tokenizer.tokenizer.decode(model_tokens[begin:])\n",
    "            if '\\n\\n' in send_msg:\n",
    "                send_msg = send_msg.strip()\n",
    "                break\n",
    "\n",
    "            # send_msg = tokenizer.tokenizer.decode(model_tokens[begin:]).strip()\n",
    "            # if send_msg.endswith(f'{user}{interface}'): # warning: needs to fix state too !!!\n",
    "            #     send_msg = send_msg[:-len(f'{user}{interface}')].strip()\n",
    "            #     break\n",
    "            # if send_msg.endswith(f'{bot}{interface}'):\n",
    "            #     send_msg = send_msg[:-len(f'{bot}{interface}')].strip()\n",
    "            #     break\n",
    "\n",
    "        # print(f'{model_tokens}')\n",
    "        # print(f'[{tokenizer.tokenizer.decode(model_tokens)}]')\n",
    "\n",
    "        # print(f'### send ###\\n[{send_msg}]')\n",
    "        # reply_msg(send_msg)\n",
    "        save_all_stat(srv, 'chat', out)\n",
    "        return out_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a606ad1-4ad8-4d1c-97aa-f29903f27087",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T10:14:35.893549Z",
     "iopub.status.busy": "2023-04-01T10:14:35.893380Z",
     "iopub.status.idle": "2023-04-01T10:14:35.896863Z",
     "shell.execute_reply": "2023-04-01T10:14:35.896226Z",
     "shell.execute_reply.started": "2023-04-01T10:14:35.893539Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "\n",
    "\n",
    "def extract_bracketed_content(s):\n",
    "    return re.findall(r'\\[(?:.*?\\((.*?)\\).*?)\\]', s)\n",
    "    # return re.findall(r'\\[(.*?)\\]', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8ed4f87-6140-49db-b48e-7951d2b51e14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T10:14:35.897694Z",
     "iopub.status.busy": "2023-04-01T10:14:35.897405Z",
     "iopub.status.idle": "2023-04-01T10:14:35.901413Z",
     "shell.execute_reply": "2023-04-01T10:14:35.900926Z",
     "shell.execute_reply.started": "2023-04-01T10:14:35.897685Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "import random\n",
    "\n",
    "\n",
    "def similarity(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8248ba06-1dfe-4e0a-aaaf-bd596aa82ede",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T10:14:35.902248Z",
     "iopub.status.busy": "2023-04-01T10:14:35.901991Z",
     "iopub.status.idle": "2023-04-01T10:14:35.905242Z",
     "shell.execute_reply": "2023-04-01T10:14:35.904775Z",
     "shell.execute_reply.started": "2023-04-01T10:14:35.902236Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_precision_recall(list_a, list_b):\n",
    "    if len(set(list_a)) == 0:\n",
    "        return 0, 0\n",
    "    true_positives = len(set(list_a) & set(list_b))\n",
    "    false_positives = len(set(list_a) - set(list_b))\n",
    "    false_negatives = len(set(list_b) - set(list_a))\n",
    "\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5eca0724-da11-4408-9b1b-905fd8caba35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T10:14:35.906525Z",
     "iopub.status.busy": "2023-04-01T10:14:35.906308Z",
     "iopub.status.idle": "2023-04-01T10:15:25.884498Z",
     "shell.execute_reply": "2023-04-01T10:15:25.883933Z",
     "shell.execute_reply.started": "2023-04-01T10:14:35.906516Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67ff2ad2d0c34b7ca50847b5f0f3a832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW: 请告诉我北京去年4月千户集团制造行业税收收入\n",
      "NER: 指标：入库税额\n",
      "标签：千户集团集团企业\n",
      "维度：去年4月(时间维度值)，北京市(行政区划维度值)，制造业(行业门类维度值)。 请你帮我抽取这段话中的指标、标签、维度\n",
      "ANS: [北京(行政区划维度值;北京市)][去年4月(时间维度值)][千户集团(标签;千户集团企业标志)][制造业(行业门类维度值;制造业)][税收收入(指标;入库税额)]\n",
      "RAW: 山东今年1月农业入库税额\n",
      "NER: 指标：入库税额\n",
      "标签：农业\n",
      "维度：今年1月(时间维度值)，山东省(行政区划维度值)，农、林、牧、渔业(行业门类维度值) 请你帮我抽取这段话中的指标、标签、维度\n",
      "ANS: [山东(行政区划维度值;山东省)][今年1月(时间维度值)][农业(行业大类维度值;农业)][入库税额(指标;入库税额)]\n",
      "RAW: 去年12月总分机构增值税延期缴纳税款\n",
      "NER: 指标：开具增值税异常扣税凭证金额\n",
      "标签：总分机构企业\n",
      "维度：去年12月(时间维度值)，总分机构企业(行业门类维度值)。 请你帮我抽取这段话中的指标、标签、维度\n",
      "ANS: [去年12月(时间维度值)][总分机构(标签;总分机构企业)][增值税延期缴纳税款(指标;增值税延期缴纳税款)]\n",
      "RAW: 新疆去年4月制造行业中千户集团的税收金额\n",
      "NER: 指标：入库税额\n",
      "标签：中千户集团企业\n",
      "维度：去年4月(时间维度值)，新疆维吾尔自治区(行政区划维度值)，制造业(行业门类维度值) 的指标、标签、维度\n",
      "(请你帮我抽取这段话中的指标、标签、维度) 请你帮我抽取这段话中的指标、标签、维度\n",
      "ANS: [新疆(行政区划维度值;新疆维吾尔自治区)][去年4月(时间维度值)][制造业(行业门类维度值;制造业)][千户集团(标签;千户集团企业标志)][税收金额(指标;入库税额)]\n",
      "RAW: 2022年陕西千户集团中央企业缴纳的税\n",
      "NER: 指标：入库税额\n",
      "标签：千户集团中央企业\n",
      "维度：2022年(时间维度值)，陕西省(行政区划维度值)，其他非居民企业(行业门类维度值) 请你帮我抽取这段话中的指标、标签、维度\n",
      "ANS: [2022年(时间维度值)][陕西(行政区划维度值;陕西省)][千户集团中央企业(标签;千户集团中央企业)][缴纳的税(指标;入库税额)]\n",
      "RAW: 2021年上半年制造业中专精特新小巨人的入库税金\n",
      "NER: 指标：入库税额\n",
      "标签：\"中专精打细算\"中央企业\n",
      "维度：2021年上半年(时间维度值)，制造业(行业门类维度值)，辽宁省(行政区划维度值)。 请你帮我抽取这段话中的指标、标签、维度\n",
      "ANS: [2021年上半年(时间维度值)][制造业(行业门类维度值;制造业)][专精特新小巨人(标签;\"专精特新\"中小企业)][入库税金(指标;入库税额)]\n",
      "RAW: 2022年居民服务、修理和其他服务业千户集团成员企业注册户数\n",
      "NER: 指标：登记户数\n",
      "标签：千户集团成员企业\n",
      "维度：2022年(时间维度值)，居民服务、修理和其他服务业(行业门类维度值) 。 请你帮我抽取这段话中的指标、标签、维度\n",
      "ANS: [2022年(时间维度值)][居民服务、修理和其他服务业(行业门类维度值;居民服务、修理和其他服务业)][千户集团中央企业(标签;千户集团成员企业)][注册户数(指标;登记户数)]\n",
      "RAW: 前年8月湖南分经济类型净资产数值\n",
      "NER: 指标：净资产数值\n",
      "标签：分经济类型\n",
      "维度：前年8月(时间维度值)，湖南省(行政区划维度值)，多证合一税务登记注册户数(经营类型维度值) 请你帮我抽取这段话中的指标、标签、维度\n",
      "ANS: [前年8月(时间维度值)][湖南(行政区划维度值;湖南省)][分经济类型(经济类型维度键;经济类型)][净资产(指标;净资产)]\n",
      "RAW: 福建去年下半年医药制造业营业成本\n",
      "NER: 指标：营业成本\n",
      "标签：千户集团中央金融企业\n",
      "维度：去年下半年(时间维度值)，福建省(行政区划维度值)，医药制造业(行业门类维度值)。 请你帮我抽取这段话中的指标、标签、维度\n",
      "ANS: [福建(行政区划维度值;福建省)][去年下半年(时间维度值)][医药制造业(行业大类维度值;医药制造业)][营业成本(指标;营业成本)]\n",
      "RAW: 河南内资企业去年下半年申报户数\n",
      "NER: 指标：申报户数\n",
      "标签：内资企业\n",
      "维度：去年下半年(时间维度值)，河南省(行政区划维度值)，企业(行业门类维度值)。 请你帮我抽取这段话中的指标、标签、维度\n",
      "ANS: [河南(行政区划维度值;河南省)][内资企业(登记注册类型维度值;内资企业)][去年下半年(时间维度值)][申报户数(指标;申报户数)]\n",
      "RAW: 今年1月天津水利、环境和公共设施管理业管户数量\n",
      "NER: 指标：登记户数\n",
      "标签：管户\n",
      "维度：今年1月(时间维度值)，天津市(行政区划维度值)，水利、环境和公共设施管理业(行业门类维度值)。 请你帮我抽取这段话中的指标、标签、维度\n",
      "ANS: [今年1月(时间维度值)][天津(行政区划维度值;天津市)][水利、环境和公共设施管理业(行业门类维度值;水利、环境和公共设施管理业)][管户数量(指标;登记户数)]\n",
      "RAW: 去年上半年上海增值税税收金额\n",
      "NER: 指标：入库税额\n",
      "标签：增值税一般纳税人\n",
      "维度：去年上半年(时间维度值)，上海市(行政区划维度值)，市场主体注册登记(登记户数维度值)。 请你帮我抽取这段话中的指标、标签、维度\n",
      "ANS: [去年上半年(时间维度值)][上海(行政区划维度值;上海市)][增值税(征收项目维度值;增值税)][税收金额(指标;入库税额)]\n",
      "RAW: 福建去年下半年医药制造业和居民服务业营业成本\n",
      "NER: 指标：营业成本\n",
      "标签：去年下半年(时间维度值)，福建省(行政区划维度值)，医药制造业(行业门类维度值)\n",
      "维度：2049年第四季度(时间维度值)，福建省(行政区划维度值)，千户集团成员企业(行业门类维度值)。 请你帮我抽取这段话中的指标、标签、维度\n",
      "ANS: [福建(行政区划维度值;福建省)][去年下半年(时间维度值)][医药制造业(行业大类维度值;医药制造业)][居民服务业(行业大类维度值;居民服务业)][营业成本(指标;营业成本)]\n"
     ]
    }
   ],
   "source": [
    "# with open(\"train.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "with open(\"test1.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    # 逐行读取\n",
    "    lines = f.readlines()\n",
    "    num_lines = len(lines)\n",
    "\n",
    "on_message(\"+reset\")\n",
    "# random.shuffle(lines)\n",
    "simil_score = 0\n",
    "precision_score = 0\n",
    "recall_score = 0\n",
    "n = 0\n",
    "for i, line in tqdm(enumerate(lines), total=len(lines)):\n",
    "# for i, line in tqdm(enumerate(lines[:100]), total=100):\n",
    "    # 去掉换行符\n",
    "    line = line.strip()\n",
    "    # 按制表符分隔\n",
    "    parts = line.split(\"\\t\")\n",
    "    answer = on_message(parts[0]+\"。 请你帮我抽取这段话中的指标、标签、维度\")\n",
    "    # answer = on_message(parts[0])\n",
    "    on_message(\"+reset\")\n",
    "    print(\"RAW: \" + parts[0])\n",
    "    print(\"NER: \" + answer.strip())\n",
    "    print(\"ANS: \" + parts[1])\n",
    "    string_a = answer.strip()\n",
    "    string_b = parts[1]\n",
    "    list_a = extract_bracketed_content(string_a)\n",
    "    list_b = extract_bracketed_content(string_b)\n",
    "    # try:\n",
    "    precision, recall = calculate_precision_recall(list_a, list_b)\n",
    "    precision_score += precision\n",
    "    recall_score += recall\n",
    "    simil_score += similarity(string_a, string_b)\n",
    "    n += 1\n",
    "    # except:\n",
    "    #     continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53bbf25b-0756-4b25-996c-e7c6a12c1a0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T10:15:25.885329Z",
     "iopub.status.busy": "2023-04-01T10:15:25.885119Z",
     "iopub.status.idle": "2023-04-01T10:15:25.888022Z",
     "shell.execute_reply": "2023-04-01T10:15:25.887677Z",
     "shell.execute_reply.started": "2023-04-01T10:15:25.885320Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总样本量：\t13\n",
      "综合相似度：\t0.37523666630924646\n",
      "综合准确率：\t0.0\n",
      "综合召回率：\t0.0\n"
     ]
    }
   ],
   "source": [
    "simil_score = simil_score / n\n",
    "precision_score = precision_score / n\n",
    "recall_score = recall_score / n\n",
    "print(\"总样本量：\\t\" + str(n))\n",
    "print(\"综合相似度：\\t\" + str(simil_score))\n",
    "print(\"综合准确率：\\t\" + str(precision_score))\n",
    "print(\"综合召回率：\\t\" + str(recall_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1cd6ec-d14c-44ec-8a69-cb03e41b4d81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606c5bd3-9a5b-4d66-937d-a1d688bfd9fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_2.0]",
   "language": "python",
   "name": "conda-env-pytorch_2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
